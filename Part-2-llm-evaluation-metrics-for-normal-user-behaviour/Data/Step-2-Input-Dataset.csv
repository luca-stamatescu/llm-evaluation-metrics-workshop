inputs.chat_history,user_query,agent_reply,ground_truth,retrieved_context,groundtruthcontext,selected_tool,selected_tool_ground_truth
[],Does Azure OpenAI use customer data to retrain models?,"Azure OpenAI does not use customer data to retrain models by default. However, Azure OpenAI provides a feature called ""Azure OpenAI on your data"" that allows organizations to generate customized insights, content, and searches using their designated data sources[doc0]. This feature works with the capabilities of the OpenAI models in Azure OpenAI to provide more accurate and relevant responses to user queries in natural language[doc0]. It can be integrated with customer's existing applications and workflows, offers insights into key performance indicators, and can interact with users seamlessly[doc0]. The use of customer data with Azure OpenAI on your data is optional and requires explicit integration and configuration[doc0].","No, Azure OpenAI doesn't use customer data to retrain models.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:51 Data, privacy, and security for Azure OpenAI Service - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:51 Data, privacy, and security for Azure OpenAI Service - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy 1/7\n\nData, privacy, and security for Azure\n\nOpenAI Service\nArticle \u2022 06/24/2023\n\nThis article provides details regarding how data provided by you to the Azure OpenAI\n\nservice is processed, used, and stored. Azure OpenAI stores and processes data to\n\nprovide the service and to monitor for uses that violate the applicable product terms.\n\nPlease also see the Microsoft Products and Services Data Protection Addendum ,\n\nwhich governs data processing by the Azure OpenAI Service except as otherwise\n\nprovided in the applicable Product Terms .\n\nAzure OpenAI processes the following types of data:\n\nPrompts and generated content. Prompts are submitted by the user, and content\n\nis generated by the service, via the completions, chat completions, images and\n\nembeddings operations.\n\n\uff09 Important\n\nYour prompts (inputs) and completions (outputs), your embeddings, and your\n\ntraining data:\n\nare NOT available to other customers.\n\nare NOT available to OpenAI.\n\nare NOT used to improve OpenAI models.\n\nare NOT used to improve any Microsoft or 3rd party products or services.\n\nare NOT used for automatically improving Azure OpenAI models for your use\n\nin your resource (The models are stateless, unless you explicitly fine-tune\n\nmodels with your training data).\n\nYour fine-tuned Azure OpenAI models are available exclusively for your use.\n\nThe Azure OpenAI Service is fully controlled by Microsoft; Microsoft hosts the\n\nOpenAI models in Microsoft\u2019s Azure environment and the Service does NOT\n\ninteract with any services operated by OpenAI (e.g. ChatGPT, or the OpenAI API).\n\nWhat data does the Azure OpenAI Service\n\nprocess?\n\nhttps://aka.ms/DPA\nhttps://aka.ms/DPA\nhttps://www.microsoft.com/licensing/terms/productoffering/MicrosoftAzure/MCA#ServiceSpecificTerms\nhttps://www.microsoft.com/licensing/terms/productoffering/MicrosoftAzure/MCA#ServiceSpecificTerms\n\n17/12/2023, 11:51 Data, privacy, and security for Azure OpenAI Service - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy 2/7\n\nAugmented data included with prompts. When using the \""on your data\"" feature,\n\nthe service retrieves relevant data from a configured data store and augments the\n\nprompt to produce generations that are grounded with your data.\n\nTraining & validation data. You can provide your own training data consisting of\n\nprompt-completion pairs for the purposes of fine-tuning an OpenAI model.\n\nThe diagram below illustrates how your data is processed. This diagram covers three\n\ndifferent types of processing:\n\n\ufffd. How the Azure OpenAI Service processes your prompts to generate content\n\n(including when additional data from a connected data source is added to a\n\nprompt using Azure OpenAI on your data).\n\n\ufffd. How the Azure OpenAI Service creates a fine-tuned (custom) model with your\n\ntraining data.\n\n\ufffd. How the Azure OpenAI Service and Microsoft personnel analyze prompts,\n\ncompletions and images for harmful content and for patterns suggesting the use\n\nof the service in a manner that violates the Code of Conduct or other applicable\n\nproduct terms\n\nAs depicted in the diagram above, managed customers may apply to modify abuse\n\nmonitoring .\n\nHow does the Azure OpenAI Service process\n\ndata?\n\nGenerating completions, images or embeddings\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio\nhttps://aka.ms/oai/modifiedaccess\nhttps://aka.ms/oai/modifiedaccess\nhttps://aka.ms/oai/modifiedaccess\n\n17/12/2023, 11:51 Data, privacy, and security for Azure OpenAI Service - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:51 Data, privacy, and security for Azure OpenAI Service - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/legal/cognitive-services/openai/data-privacy 3/7\n\nModels (base or fine-tuned) deployed in your resource process your input prompts and\n\ngenerate responses with text, images or embeddings. The service is configured to\n\nsynchronously evaluate the prompt and completion data in real time to check for\n\nharmful content types and stops generating content that exceeds the configured\n\nthresholds. Learn more at Azure OpenAI Service content filtering.\n\nThe models are stateless: no prompts or generations are stored in the model.\n\nAdditionally, prompts and generations are not used to train, retrain, or improve the\n\nbase models.\n\nThe Azure OpenAI \""on your data\"" feature lets you connect data sources to ground the\n\ngenerated results with your data. The data remains stored in the data source and\n\nlocation you designate. No data is copied into the Azure OpenAI service. When a user\n\nprompt is received, the service retrieves relevant data from the connected data source\n\nand augments the prompt. The model processes this augmented prompt and the\n\ngenerated content is returned as described above.\n\nAs depicted in the diagram above, managed customers may apply to modify abuse\n\nmonitoring .\n\nCustomers can upload their training data to the service to fine tune a model. Uploaded\n\ntraining data is stored in the Azure OpenAI resource in the customer\u2019s Azure tenant.\n\nAugmenting prompts with data retrieved from your data sources to\n\n\""ground\"" the generated results\n\nCreating a customized (fine-tuned) model with your data:\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\nhttps://aka.ms/oai/modifiedaccess\nhttps://aka.ms/oai/modifiedaccess\nhttps://aka.ms/oai/modifiedaccess\n\n17/12/2023, 11:51 Data, privacy, and security for Azure OpenAI Service - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy 4/7\n\nTraining data and fine-tuned models:\n\nAre available exclusively for use by the customer.\n\nAre stored within the same region as the Azure OpenAI resource.\n\nCan be double encrypted at rest (by default with Microsoft's AES-256 encryption\n\nand optionally with a customer managed key).\n\nCan be deleted by the customer at any time.\n\nTraining data uploaded for fine-tuning is not used to train, retrain, or improve any\n\nMicrosoft or 3rd party base models.\n\nTo reduce the risk of harmful use of the Azure OpenAI Service, the Azure OpenAI Service\n\nincludes both content filtering and abuse monitoring features. To learn more about\n\ncontent filtering, see Azure OpenAI Service content filtering. To learn more about abuse\n\nmonitoring, see abuse monitoring.\n\nContent filtering occurs synchronously as the service processes prompts to generate\n\ncontent as described above and here. No prompts or generated results are stored in the\n\ncontent classifier models, and prompts and results are not used to train, retrain, or\n\nimprove the classifier models.\n\nAzure OpenAI abuse monitoring detects and mitigates instances of recurring content\n\nand/or behaviors that suggest use of the service in a manner that may violate the code\n\nof conduct or other applicable product terms. To detect and mitigate abuse, Azure\n\nOpenAI stores all prompts and generated content securely for up to thirty (30) days. (No\n\nprompts or completions are stored if the customer is approved for and elects to\n\nconfigure abuse monitoring off, as described below.)\n\nThe data store where prompts and completions are stored is logically separated by\n\ncustomer resource (each request includes the resource ID of the customer\u2019s Azure\n\nOpenAI resource). A separate data store is located in each region  in which the Azure\n\nOpenAI Service is available, and a customer\u2019s prompts and generated content are stored\n\nin the Azure region where the customer\u2019s Azure OpenAI service resource is deployed,\n\nwithin the Azure OpenAI service boundary. Human reviewers assessing potential abuse\n\ncan access prompts and completions data only when that data has been flagged by the\n\nabuse monitoring system. The human reviewers are authorized Microsoft employees\n\nwho access the data via point wise queries using request IDs, Secure Access\n\nWorkstations (SAWs), and Just-In-Time (JIT) request approval granted by team\n\nmanagers""}}]}","prompts and generations are not used to train, retrain, or improve the\n\nbase models.",AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Is the latest release of the OpenAI Python library (version>=1.0) supported by Azure OpenAI?,"Yes, the latest release of the OpenAI Python library (version>=1.0) is supported by Azure OpenAI[doc0].","Yes, Azure OpenAI is supported by the latest release of the OpenAI Python library.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}]}",zure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0),AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I find GPT-4 Turbo Preview in Azure OpenAI?,"Yes, you can find GPT-4 Turbo Preview in Azure OpenAI[doc3]. It is one of the models available in Azure OpenAI Service[doc2]. However, please note that GPT-4 Turbo Preview is not recommended for production use[doc0].","Yes, GPT-4 Turbo Preview is available in Azure OpenAI.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 1/8\n\nAzure OpenAI Service models\nArticle \u2022 12/12/2023\n\nAzure OpenAI Service is powered by a diverse set of models with different capabilities\n\nand price points. Model availability varies by region. For GPT-3 and other models\n\nretiring in July 2024, see Azure OpenAI Service legacy models.\n\nModels Description\n\nGPT-4 A set of models that improve on GPT-3.5 and can understand and generate\n\nnatural language and code.\n\nGPT-3.5 A set of models that improve on GPT-3 and can understand and generate\n\nnatural language and code.\n\nEmbeddings A set of models that can convert text into numerical vector form to facilitate\n\ntext similarity.\n\nDALL-E\n\n(Preview)\n\nA series of models in preview that can generate original images from natural\n\nlanguage.\n\nWhisper\n\n(Preview)\n\nA series of models in preview that can transcribe and translate speech to text.\n\nGPT-4 can solve difficult problems with greater accuracy than any of OpenAI's previous\n\nmodels. Like GPT-3.5 Turbo, GPT-4 is optimized for chat and works well for traditional\n\ncompletions tasks. Use the Chat Completions API to use GPT-4. To learn more about\n\nhow to interact with GPT-4 and the Chat Completions API check out our in-depth how-\n\nto.\n\ngpt-4\n\ngpt-4-32k\n\ngpt-4-vision\n\nYou can see the token context length supported by each model in the model summary\n\ntable.\n\n\uff89 Expand table\n\nGPT-4 and GPT-4 Turbo Preview\n\nGPT-3.5\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/legacy-models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\n\n17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 2/8\n\nGPT-3.5 models can understand and generate natural language or code. The most\n\ncapable and cost effective model in the GPT-3.5 family is GPT-3.5 Turbo, which has been\n\noptimized for chat and works well for traditional completions tasks as well. GPT-3.5\n\nTurbo is available for use with the Chat Completions API. GPT-3.5 Turbo Instruct has\n\nsimilar capabilities to text-davinci-003  using the Completions API instead of the Chat\n\nCompletions API. We recommend using GPT-3.5 Turbo and GPT-3.5 Turbo Instruct over\n\nlegacy GPT-3.5 and GPT-3 models.\n\ngpt-35-turbo\n\ngpt-35-turbo-16k\n\ngpt-35-turbo-instruct\n\nYou can see the token context length supported by each model in the model summary\n\ntable.\n\nTo learn more about how to interact with GPT-3.5 Turbo and the Chat Completions API\n\ncheck out our in-depth how-to.\n\nThe previous embeddings models have been consolidated into the following new\n\nreplacement model:\n\ntext-embedding-ada-002\n\nThe DALL-E models, currently in preview, generate images from text prompts that the\n\nuser provides.\n\nEmbeddings\n\n\uff09 Important\n\nWe strongly recommend using text-embedding-ada-002 (Version 2) . This\n\nmodel/version provides parity with OpenAI's text-embedding-ada-002 . To learn\n\nmore about the improvements offered by this model, please refer to OpenAI's blog\n\npost . Even if you are currently using Version 1 you should migrate to Version 2 to\n\ntake advantage of the latest weights/updated token limit""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}]}",GPT-4 Turbo Preview is the gpt-4 (1106-preview) model,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Does Azure OpenAI support GPT-4 models?,"Yes, Azure OpenAI Service supports GPT-4 models[doc0][doc1][doc2]. GPT-4 is a set of models that improve on GPT-3 and can understand and generate natural language and code[doc0]. It is optimized for chat and works well for traditional completions tasks[doc0]. You can use the Chat Completions API to interact with GPT-4[doc0]. However, the availability of GPT-4 models may vary by region, so it's recommended to check the availability in your specific region[doc1][doc2].","Yes, Azure OpenAI supports the latest GPT-4 models.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn"", ""content"": ""Embedding input array increase\n\nNew Regions\n\nJune 2023\n\nUse Azure OpenAI on your own data (preview)\n\nNew versions of gpt-35-turbo and gpt-4 models\n\nUK South\n\nContent filtering & annotations (Preview)\n\nQuota\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/switching-endpoints#azure-openai-embeddings-multiple-input-support\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/content-filters\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\n\n17/12/2023, 11:50 What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new 7/11\n\nQuota provides the flexibility to actively manage the allocation of rate limits across\n\nthe deployments within your subscription.\n\nNEW Azure OpenAI preview SDKs offering support for JavaScript and Java.\n\nGeneral availability support for:\n\nChat Completion API version 2023-05-15 .\n\nGPT-35-Turbo models.\n\nGPT-4 model series.\n\nIf you are currently using the 2023-03-15-preview  API, we recommend migrating to\n\nthe GA 2023-05-15  API. If you are currently using API version 2022-12-01  this API\n\nremains GA, but does not include the latest Chat Completion capabilities.\n\nAzure OpenAI is now available in the France Central region. Check the models\n\npage, for the latest information on model availability in each region.\n\nDALL-E 2 public preview. Azure OpenAI Service now supports image generation\n\nAPIs powered by OpenAI's DALL-E 2 model. Get AI-generated images based on\n\nthe descriptive text you provide. To learn more, check out the quickstart. To\n\nrequest access, existing Azure OpenAI customers can apply by filling out this\n\nform .\n\nMay 2023\n\nJava & JavaScript SDK support\n\nAzure OpenAI Chat Completion General Availability (GA)\n\n\uff09 Important\n\nUsing the current versions of the GPT-35-Turbo models with the completion\n\nendpoint remains in preview.\n\nFrance Central\n\nApril 2023\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line&pivots=programming-language-javascript\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line&pivots=programming-language-java\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/dall-e-quickstart\nhttps://aka.ms/oai/access\nhttps://aka.ms/oai/access\nhttps://aka.ms/oai/access\n\n17/12/2023, 11:50 What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new 8/11\n\nInactive deployments of customized models will now be deleted after 15 days;\n\nmodels will remain available for redeployment""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn"", ""content"": ""To deploy this model,\n\nunder Deployments select model gpt-4. For Model version select vision-preview.\n\nModel Availability gpt-4\n\n(0314)\n\ngpt-4 (0613) gpt-4 (1106-\n\npreview)\n\ngpt-4  (vision-\n\npreview)\n\nAvailable to all subscriptions with\n\nAzure OpenAI access\n\nAustralia East\n\nCanada East\n\nFrance\n\nCentral\n\nAustralia East\n\nCanada East\n\nEast US 2\n\nFrance\n\nAustralia East\n\nSweden Central\n\nSwitzerland\n\n1\n\n2\n\n1\n\n2\n\n\uff35 Caution\n\nWe don't recommend using these models in production. We will upgrade all\n\ndeployments of these models to a future stable version. Models designated\n\npreview do not follow the standard Azure OpenAI model lifecycle.\n\n\uff17 Note\n\nRegions where GPT-4 (0314) & (0613) are listed as available have access to both\n\nthe 8K and 32K versions of the model\n\nGPT-4 and GPT-4 Turbo Preview model availability\n\n\uff89 Expand table\n\n17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 5/8\n\nModel Availability gpt-4\n\n(0314)\n\ngpt-4 (0613) gpt-4 (1106-\n\npreview)\n\ngpt-4  (vision-\n\npreview)\n\nSweden\n\nCentral\n\nSwitzerland\n\nNorth\n\nCentral\n\nNorway East\n\nSouth India\n\nSweden\n\nCentral\n\nUK South\n\nWest US\n\nNorth\n\nWest US\n\nAvailable to subscriptions with\n\ncurrent access to the model\n\nversion in the region\n\nEast US\n\nFrance\n\nCentral\n\nSouth\n\nCentral\n\nUS\n\nUK South\n\nEast US\n\nEast US 2\n\nJapan East\n\nUK South\n\nGPT-3.5 Turbo is used with the Chat Completion API. GPT-3.5 Turbo version 0301 can\n\nalso be used with the Completions API. GPT-3.5 Turbo versions 0613 and 1106 only\n\nsupport the Chat Completions API.\n\nGPT-3.5 Turbo version 0301 is the first version of the model released. Version 0613 is\n\nthe second version of the model and adds function calling support.\n\nSee model versions to learn about how Azure OpenAI Service handles model version\n\nupgrades, and working with models to learn how to view and configure the model\n\nversion settings of your GPT-3.5 Turbo deployments.\n\nGPT-3.5 models\n\n\uff17 Note\n\nVersion 0301  of gpt-35-turbo  will be retired no earlier than July 5, 2024. See\n\nmodel updates for model upgrade behavior.\n\nGPT-3.5-Turbo model availability\n\n\uff89 Expand table\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/model-versions\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/working-with-models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/working-with-models#model-updates\n\n17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc2]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}]}",Azure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Are VNETs and Private Endpoints supported by Azure OpenAI?,"Yes, VNETs (Virtual Networks) and Private Endpoints are supported by Azure OpenAI[doc0]. Azure OpenAI, as part of Azure AI services, provides support for VNETs and Private Endpoints[doc0].","Yes, Azure OpenAI supports VNETs and Private Endpoints.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}]}",Azure OpenAI supports VNETs and Private Endpoints.,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Do the GPT-4 models currently support image input?,The GPT-4 models currently do not support image input[doc1][doc2].,"No, currently only text input and output are supported for GPT-4 models.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}]}","GPT-4 is designed by OpenAI to be multimodal, but currently only text input and output are supported",AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Is there a token limit on the system message for Azure OpenAI on your data?,"Yes, there is a token limit on the system message for Azure OpenAI on your data. The token limit is 400 tokens. If the system message exceeds 400 tokens, only the first 400 tokens will be considered, and the rest will be ignored. Please note that this limitation applies specifically to the Azure OpenAI on your data feature[doc0].","Yes, the token limit on the system message is 400.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""How can I customize or automate the index\n\ncreation process?\n\nHow can I update my index?\n\nWhat file types does Azure OpenAI on your data\n\nsupport?\n\nIs responsible AI supported by Azure OpenAI on\n\nyour data?\n\nIs there a token limit on the system message?\n\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#schedule-automatic-index-refreshes\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#data-formats-and-file-types\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=text\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 12/13\n\nAzure OpenAI on your data currently doesn't support function calling.\n\nYou must send queries in the same language of your data. Your data can be in any of\n\nthe languages supported by Azure AI Search.\n\nWhen you select \""Azure AI Search\"" as the data source, you can choose to apply\n\nsemantic search. If you select \""Azure Blob Container\"" or \""Upload files\"" as the data\n\nsource, you can create the index as usual. Afterwards you would re-ingest the data using\n\nthe \""Azure AI Search\"" option to select the same index and apply Semantic Search. You\n\nwill then be ready to chat on your data with semantic search applied.\n\nWhen you select \""Azure Blob Container\"", \""Azure AI Search\"", or \""Upload files\"" as the data\n\nsource, you can also select an Ada embedding model deployment to use when\n\ningesting your data. This will create an Azure AI Search index with vector embeddings.\n\nIndex creation can fail when adding embeddings to your index if the rate limit on your\n\nAda embedding model deployment is too low, or if you have a very large set of\n\ndocuments. You can use this script provided on GitHub  to create the index with\n\nembeddings manually.\n\nDoes Azure OpenAI on your data support\n\nfunction calling?\n\nDoes the query language and the data source\n\nlanguage need to be the same?\n\nIf Semantic Search is enabled for my Azure AI\n\nSearch resource, will it be automatically applied\n\nto Azure OpenAI on your data in the Azure\n\nOpenAI Studio?\n\nHow can I add vector embeddings when\n\nindexing my data?\n\nWhy is index creation failing after I added an\n\nembedding model?\n\nhttps://learn.microsoft.com/en-us/azure/search/search-language-support\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""How can I customize or automate the index\n\ncreation process?\n\nHow can I update my index?\n\nWhat file types does Azure OpenAI on your data\n\nsupport?\n\nIs responsible AI supported by Azure OpenAI on\n\nyour data?\n\nIs there a token limit on the system message?\n\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#schedule-automatic-index-refreshes\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#data-formats-and-file-types\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=text\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 12/13\n\nAzure OpenAI on your data currently doesn't support function calling.\n\nYou must send queries in the same language of your data. Your data can be in any of\n\nthe languages supported by Azure AI Search.\n\nWhen you select \""Azure AI Search\"" as the data source, you can choose to apply\n\nsemantic search. If you select \""Azure Blob Container\"" or \""Upload files\"" as the data\n\nsource, you can create the index as usual. Afterwards you would re-ingest the data using\n\nthe \""Azure AI Search\"" option to select the same index and apply Semantic Search. You\n\nwill then be ready to chat on your data with semantic search applied.\n\nWhen you select \""Azure Blob Container\"", \""Azure AI Search\"", or \""Upload files\"" as the data\n\nsource, you can also select an Ada embedding model deployment to use when\n\ningesting your data. This will create an Azure AI Search index with vector embeddings.\n\nIndex creation can fail when adding embeddings to your index if the rate limit on your\n\nAda embedding model deployment is too low, or if you have a very large set of\n\ndocuments. You can use this script provided on GitHub  to create the index with\n\nembeddings manually.\n\nDoes Azure OpenAI on your data support\n\nfunction calling?\n\nDoes the query language and the data source\n\nlanguage need to be the same?\n\nIf Semantic Search is enabled for my Azure AI\n\nSearch resource, will it be automatically applied\n\nto Azure OpenAI on your data in the Azure\n\nOpenAI Studio?\n\nHow can I add vector embeddings when\n\nindexing my data?\n\nWhy is index creation failing after I added an\n\nembedding model?\n\nhttps://learn.microsoft.com/en-us/azure/search/search-language-support\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}]}",the token limit on the system message is 400,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I use GPT-4 to generate images?,"No, you cannot use GPT-4 to generate images. Instead, you can use the model called ""dall-e-3"" to generate images[doc0][doc1].","No, you cannot use GPT-4 to generate images, but you can use DALL-E models.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 1/8\n\nAzure OpenAI Service models\nArticle \u2022 12/12/2023\n\nAzure OpenAI Service is powered by a diverse set of models with different capabilities\n\nand price points. Model availability varies by region. For GPT-3 and other models\n\nretiring in July 2024, see Azure OpenAI Service legacy models.\n\nModels Description\n\nGPT-4 A set of models that improve on GPT-3.5 and can understand and generate\n\nnatural language and code.\n\nGPT-3.5 A set of models that improve on GPT-3 and can understand and generate\n\nnatural language and code.\n\nEmbeddings A set of models that can convert text into numerical vector form to facilitate\n\ntext similarity.\n\nDALL-E\n\n(Preview)\n\nA series of models in preview that can generate original images from natural\n\nlanguage.\n\nWhisper\n\n(Preview)\n\nA series of models in preview that can transcribe and translate speech to text.\n\nGPT-4 can solve difficult problems with greater accuracy than any of OpenAI's previous\n\nmodels. Like GPT-3.5 Turbo, GPT-4 is optimized for chat and works well for traditional\n\ncompletions tasks. Use the Chat Completions API to use GPT-4. To learn more about\n\nhow to interact with GPT-4 and the Chat Completions API check out our in-depth how-\n\nto.\n\ngpt-4\n\ngpt-4-32k\n\ngpt-4-vision\n\nYou can see the token context length supported by each model in the model summary\n\ntable.\n\n\uff89 Expand table\n\nGPT-4 and GPT-4 Turbo Preview\n\nGPT-3.5\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/legacy-models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\n\n17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 2/8\n\nGPT-3.5 models can understand and generate natural language or code. The most\n\ncapable and cost effective model in the GPT-3.5 family is GPT-3.5 Turbo, which has been\n\noptimized for chat and works well for traditional completions tasks as well. GPT-3.5\n\nTurbo is available for use with the Chat Completions API. GPT-3.5 Turbo Instruct has\n\nsimilar capabilities to text-davinci-003  using the Completions API instead of the Chat\n\nCompletions API. We recommend using GPT-3.5 Turbo and GPT-3.5 Turbo Instruct over\n\nlegacy GPT-3.5 and GPT-3 models.\n\ngpt-35-turbo\n\ngpt-35-turbo-16k\n\ngpt-35-turbo-instruct\n\nYou can see the token context length supported by each model in the model summary\n\ntable.\n\nTo learn more about how to interact with GPT-3.5 Turbo and the Chat Completions API\n\ncheck out our in-depth how-to.\n\nThe previous embeddings models have been consolidated into the following new\n\nreplacement model:\n\ntext-embedding-ada-002\n\nThe DALL-E models, currently in preview, generate images from text prompts that the\n\nuser provides.\n\nEmbeddings\n\n\uff09 Important\n\nWe strongly recommend using text-embedding-ada-002 (Version 2) . This\n\nmodel/version provides parity with OpenAI's text-embedding-ada-002 . To learn\n\nmore about the improvements offered by this model, please refer to OpenAI's blog\n\npost . Even if you are currently using Version 1 you should migrate to Version 2 to\n\ntake advantage of the latest weights/updated token limit""}}]}",you can use dall-e-3 to generate images,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],What is the maximum number of fine-tuned models I can create?,The maximum number of fine-tuned models that can be created in Azure OpenAI Service is 100[doc0].,You can create a maximum of 100 fine-tuned models.,"{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""After I apply for access, how long will I have to\n\nwait to get approved?\n\nLearning more and where to ask\n\nquestions\n\nWhere can I read about the latest updates to\n\nAzure OpenAI?\n\nWhere can I get training to get started learning\n\nand build my skills around Azure OpenAI?\n\nWhere can I post questions and see answers to\n\nother common questions?\n\nWhere do I go for Azure OpenAI customer\n\nsupport?\n\nModels and fine-tuning\n\nhttps://aka.ms/oaiapply\nhttps://aka.ms/oaiapply\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new\nhttps://learn.microsoft.com/en-us/training/modules/explore-azure-openai/\nhttps://learn.microsoft.com/en-us/answers/tags/387/azure-openai\nhttps://stackoverflow.com/search?q=azure+openai\nhttps://stackoverflow.com/search?q=azure+openai\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/cognitive-services/openai/context/context\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 7/13\n\nConsult the Azure OpenAI model availability guide.\n\nConsult the Azure OpenAI model availability guide for region availability.\n\nIn order to successfully access fine-tuning, you need Cognitive Services OpenAI\n\nContributor assigned. Even someone with high-level Service Administrator permissions\n\nwould still need this account explicitly set in order to access fine-tuning. For more\n\ninformation, please review the role-based access control guidance.\n\nA base model is a model that hasn't been customized or fine-tuned for a specific use\n\ncase. Fine-tuned models are customized versions of base models where a model's\n\nweights are trained on a unique set of prompts. Fine-tuned models let you achieve\n\nbetter results on a wider number of tasks without needing to provide detailed examples\n\nfor in-context learning as part of your completion prompt. To learn more, review our\n\nfine-tuning guide.\n\n100\n\nWe don't have a defined API response time Service Level Agreement (SLA) at this time.\n\nFor more information about the SLA for Azure OpenAI Service, see the Service Level\n\nAgreements (SLA) for Online Services page .\n\nWhat models are available?\n\nWhere can I find out what region a model is\n\navailable in?\n\nHow do I enable fine-tuning? Create a custom\n\nmodel is greyed out in Azure OpenAI Studio.\n\nWhat is the difference between a base model\n\nand a fine-tuned model?\n\nWhat is the maximum number of fine-tuned\n\nmodels I can create?\n\nWhat are the SLAs for API responses in Azure\n\nOpenAI?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/role-based-access-control#cognitive-services-openai-contributor\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio\nhttps://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/\nhttps://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/\nhttps://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}]}",100,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Is there a defined API response time SLA for Azure OpenAI?,The retrieved documents do not provide information about a defined API response time Service Level Agreement (SLA) for Azure OpenAI Service [doc0].,"No, there is no defined API response time SLA at this time.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""After I apply for access, how long will I have to\n\nwait to get approved?\n\nLearning more and where to ask\n\nquestions\n\nWhere can I read about the latest updates to\n\nAzure OpenAI?\n\nWhere can I get training to get started learning\n\nand build my skills around Azure OpenAI?\n\nWhere can I post questions and see answers to\n\nother common questions?\n\nWhere do I go for Azure OpenAI customer\n\nsupport?\n\nModels and fine-tuning\n\nhttps://aka.ms/oaiapply\nhttps://aka.ms/oaiapply\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new\nhttps://learn.microsoft.com/en-us/training/modules/explore-azure-openai/\nhttps://learn.microsoft.com/en-us/answers/tags/387/azure-openai\nhttps://stackoverflow.com/search?q=azure+openai\nhttps://stackoverflow.com/search?q=azure+openai\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/cognitive-services/openai/context/context\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 7/13\n\nConsult the Azure OpenAI model availability guide.\n\nConsult the Azure OpenAI model availability guide for region availability.\n\nIn order to successfully access fine-tuning, you need Cognitive Services OpenAI\n\nContributor assigned. Even someone with high-level Service Administrator permissions\n\nwould still need this account explicitly set in order to access fine-tuning. For more\n\ninformation, please review the role-based access control guidance.\n\nA base model is a model that hasn't been customized or fine-tuned for a specific use\n\ncase. Fine-tuned models are customized versions of base models where a model's\n\nweights are trained on a unique set of prompts. Fine-tuned models let you achieve\n\nbetter results on a wider number of tasks without needing to provide detailed examples\n\nfor in-context learning as part of your completion prompt. To learn more, review our\n\nfine-tuning guide.\n\n100\n\nWe don't have a defined API response time Service Level Agreement (SLA) at this time.\n\nFor more information about the SLA for Azure OpenAI Service, see the Service Level\n\nAgreements (SLA) for Online Services page .\n\nWhat models are available?\n\nWhere can I find out what region a model is\n\navailable in?\n\nHow do I enable fine-tuning? Create a custom\n\nmodel is greyed out in Azure OpenAI Studio.\n\nWhat is the difference between a base model\n\nand a fine-tuned model?\n\nWhat is the maximum number of fine-tuned\n\nmodels I can create?\n\nWhat are the SLAs for API responses in Azure\n\nOpenAI?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/role-based-access-control#cognitive-services-openai-contributor\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio\nhttps://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/\nhttps://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/\nhttps://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview 1/5\n\nWhat is Azure OpenAI Service?\nArticle \u2022 12/12/2023\n\nAzure OpenAI Service provides REST API access to OpenAI's powerful language models\n\nincluding the GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, and Embeddings model\n\nseries. In addition, the new GPT-4 and GPT-3.5-Turbo model series have now reached\n\ngeneral availability. These models can be easily adapted to your specific task including\n\nbut not limited to content generation, summarization, image understanding, semantic\n\nsearch, and natural language to code translation. Users can access the service through\n\nREST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\n\nFeature Azure OpenAI\n\nModels available GPT-4 series (including GPT-4 Turbo with Vision)\n\nGPT-3.5-Turbo series\n\nEmbeddings series\n\nLearn more in our Models page.\n\nFine-tuning (preview) GPT-3.5-Turbo  (0613)\n\nbabbage-002\n\ndavinci-002 .\n\nPrice Available here\n\nVirtual network support &\n\nprivate link support\n\nYes, unless using Azure OpenAI on your data.\n\nManaged Identity Yes, via Microsoft Entra ID\n\nUI experience Azure portal for account & resource management,\n\nAzure OpenAI Service Studio for model exploration and fine-\n\ntuning\n\nModel regional availability Model availability\n\nContent filtering Prompts and completions are evaluated against our content policy\n\nwith automated systems. High severity content will be filtered.\n\nFeatures overview\n\n\uff89 Expand table\n\nResponsible AI\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\nhttps://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview 2/5\n\nAt Microsoft, we're committed to the advancement of AI driven by principles that put\n\npeople first. Generative models such as the ones available in Azure OpenAI have\n\nsignificant potential benefits, but without careful design and thoughtful mitigations,\n\nsuch models have the potential to generate incorrect or even harmful content. Microsoft\n\nhas made significant investments to help guard against abuse and unintended harm,\n\nwhich includes requiring applicants to show well-defined use cases, incorporating\n\nMicrosoft\u2019s principles for responsible AI use , building content filters to support\n\ncustomers, and providing responsible AI implementation guidance to onboarded\n\ncustomers.\n\nHow do I get access to Azure OpenAI?\n\nAccess is currently limited as we navigate high demand, upcoming product\n\nimprovements, and Microsoft\u2019s commitment to responsible AI . For now, we're\n\nworking with customers with an existing partnership with Microsoft, lower risk use cases,\n\nand those committed to incorporating mitigations.\n\nMore specific information is included in the application form. We appreciate your\n\npatience as we work to responsibly enable broader access to Azure OpenAI.\n\nApply here for access:\n\nApply now\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-4, GPT-\n\n3, Codex, DALL-E, and Whisper models with the security and enterprise promise of\n\nAzure. Azure OpenAI co-develops the APIs with OpenAI, ensuring compatibility and a\n\nsmooth transition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI. Azure OpenAI offers private networking, regional\n\navailability, and responsible AI content filtering""}}, {""[doc2]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service fine-tuning considerations - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/concepts/fine-tuning-considerations 4/4\n\nAnother important point is even with high quality data if your data isn't in the necessary\n\nformat for fine-tuning you'll need to commit engineering resources in order to properly\n\nformat the data.\n\nData Babbage-002 & Davinci-002 GPT-3.5-Turbo\n\nVolume Thousands of Examples Thousands of Examples\n\nFormat Prompt/Completion Conversational Chat\n\nIf you are ready for fine-tuning you:\n\nHave identified a dataset for fine-tuning.\n\nThe dataset is in the appropriate format for training.\n\nSome level of curation has been employed to ensure dataset quality.\n\nCommon signs you might not be ready for fine-tuning yet:\n\nDataset hasn't been identified yet.\n\nDataset format doesn't match the model you wish to fine-tune.\n\nThere isn\u2019t a single right answer to this question, but you should have clearly defined\n\ngoals for what success with fine-tuning looks like. Ideally, this shouldn't just be\n\nqualitative but should include quantitative measures of success like utilizing a holdout\n\nset of data for validation, as well as user acceptance testing or A/B testing the fine-\n\ntuned model against a base model.\n\nWatch the Azure AI Show episode: \""To fine-tune or not to fine-tune, that is the\n\nquestion\""\n\nLearn more about Azure OpenAI fine-tuning\n\nExplore our fine-tuning tutorial\n\n\uff89 Expand table\n\nHow will you measure the quality of your fine-\n\ntuned model?\n\nNext steps\n\nhttps://www.youtube.com/watch?v=0Jo-z-MFxJs\nhttps://www.youtube.com/watch?v=0Jo-z-MFxJs\nhttps://www.youtube.com/watch?v=0Jo-z-MFxJs\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune""}}]}",We don't have a defined API response time Service Level Agreement (SLA) at this time.,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Does Azure OpenAI on your data support function calling?,"Yes, Azure OpenAI on your data does support function calling[doc1].","No, Azure OpenAI on your data currently doesn't support function calling.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn"", ""content"": ""Check the models page, for the latest information on model availability in\n\neach region.\n\nIncreases to the max default quota limits for certain models and regions. Migrating\n\nworkloads to these models and regions will allow you to take advantage of higher\n\nTokens per minute (TPM).\n\nYou can now deploy Azure OpenAI on your data to Power Virtual Agents.\n\nAzure OpenAI on your data now supports private endpoints.\n\nAbility to filter access to sensitive documents.\n\nAutomatically refresh your index on a schedule.\n\nVector search and semantic search options.\n\nView your chat history in the deployed web app\n\nAzure OpenAI now supports function calling to enable you to work with functions\n\nin the chat completions API.\n\n\uff17 Note\n\nAzure AI Speech also supports OpenAI's Whisper model via the batch transcription\n\nAPI. To learn more, check out the Create a batch transcription guide. Check out\n\nWhat is the Whisper model? to learn more about when to use Azure AI Speech vs.\n\nAzure OpenAI Service.\n\nNew Regions\n\nRegional quota limits increases\n\nAugust 2023\n\nAzure OpenAI on your own data (preview) updates\n\nJuly 2023\n\nSupport for function calling\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits#regional-quota-limits\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#deploying-the-model\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#virtual-network-support--private-endpoint-support\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#document-level-access-control\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#schedule-automatic-index-refreshes\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#search-options\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#chat-history\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/batch-transcription-create#using-whisper-models\nhttps://learn.microsoft.com/en-us/azure/ai-services/speech-service/whisper-overview\n\n17/12/2023, 11:50 What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new 6/11\n\nAzure OpenAI now supports arrays with up to 16 inputs per API request with text-\n\nembedding-ada-002 Version 2.\n\nAzure OpenAI is now also available in the Canada East, East US 2, Japan East, and\n\nNorth Central US regions. Check the models page, for the latest information on\n\nmodel availability in each region.\n\nAzure OpenAI on your data is now available in preview, enabling you to chat with\n\nOpenAI models such as GPT-35-Turbo and GPT-4 and receive responses based on\n\nyour data.\n\ngpt-35-turbo (version 0613)\n\ngpt-35-turbo-16k (version 0613)\n\ngpt-4 (version 0613)\n\ngpt-4-32k (version 0613)\n\nAzure OpenAI is now available in the UK South region. Check the models page, for\n\nthe latest information on model availability in each region.\n\nHow to configure content filters with Azure OpenAI Service.\n\nEnable annotations to view content filtering category and severity information as\n\npart of your GPT based Completion and Chat Completion calls""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""How can I customize or automate the index\n\ncreation process?\n\nHow can I update my index?\n\nWhat file types does Azure OpenAI on your data\n\nsupport?\n\nIs responsible AI supported by Azure OpenAI on\n\nyour data?\n\nIs there a token limit on the system message?\n\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#schedule-automatic-index-refreshes\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#data-formats-and-file-types\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=text\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 12/13\n\nAzure OpenAI on your data currently doesn't support function calling.\n\nYou must send queries in the same language of your data. Your data can be in any of\n\nthe languages supported by Azure AI Search.\n\nWhen you select \""Azure AI Search\"" as the data source, you can choose to apply\n\nsemantic search. If you select \""Azure Blob Container\"" or \""Upload files\"" as the data\n\nsource, you can create the index as usual. Afterwards you would re-ingest the data using\n\nthe \""Azure AI Search\"" option to select the same index and apply Semantic Search. You\n\nwill then be ready to chat on your data with semantic search applied.\n\nWhen you select \""Azure Blob Container\"", \""Azure AI Search\"", or \""Upload files\"" as the data\n\nsource, you can also select an Ada embedding model deployment to use when\n\ningesting your data. This will create an Azure AI Search index with vector embeddings.\n\nIndex creation can fail when adding embeddings to your index if the rate limit on your\n\nAda embedding model deployment is too low, or if you have a very large set of\n\ndocuments. You can use this script provided on GitHub  to create the index with\n\nembeddings manually.\n\nDoes Azure OpenAI on your data support\n\nfunction calling?\n\nDoes the query language and the data source\n\nlanguage need to be the same?\n\nIf Semantic Search is enabled for my Azure AI\n\nSearch resource, will it be automatically applied\n\nto Azure OpenAI on your data in the Azure\n\nOpenAI Studio?\n\nHow can I add vector embeddings when\n\nindexing my data?\n\nWhy is index creation failing after I added an\n\nembedding model?\n\nhttps://learn.microsoft.com/en-us/azure/search/search-language-support\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}]}",Azure OpenAI on your data currently doesn't support function calling,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Is there a limit to the size of the image I can upload?,"Yes, there is a limit to the size of the image you can upload. The Azure OpenAI Service restricts image uploads to 20MB per image[doc0][doc1].","Yes, there is a 20MB limit per image upload.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn"", ""content"": ""How do I get access to Azure OpenAI?\n\nComparing Azure OpenAI and OpenAI\n\nKey concepts\n\nPrompts & completions\n\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://aka.ms/oaiapply\nhttps://aka.ms/oaiapply\n\n17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview 3/5\n\nThe completions endpoint is the core component of the API service. This API provides\n\naccess to the model's text-in, text-out interface. Users simply need to provide an input\n\nprompt containing the English text command, and the model will generate a text\n\ncompletion.\n\nHere's an example of a simple prompt and completion:\n\nPrompt: \""\""\"" count to 5 in a for loop \""\""\""\n\nCompletion: for i in range(1, 6): print(i)\n\nAzure OpenAI processes text by breaking it down into tokens. Tokens can be words or\n\njust chunks of characters. For example, the word \u201chamburger\u201d gets broken up into the\n\ntokens \u201cham\u201d, \u201cbur\u201d and \u201cger\u201d, while a short and common word like \u201cpear\u201d is a single\n\ntoken. Many tokens start with a whitespace, for example \u201c hello\u201d and \u201c bye\u201d.\n\nThe total number of tokens processed in a given request depends on the length of your\n\ninput, output and request parameters. The quantity of tokens being processed will also\n\naffect your response latency and throughput for the models.\n\nThe token cost of an input image depends on two main factors: the size of the image\n\nand the detail setting (low or high) used for each image. Here's a breakdown of how it\n\nworks:\n\nDetail: Low resolution mode\n\nLow detail allows the API to return faster responses and consume fewer input\n\ntokens for use cases that don\u2019t require high detail.\n\nThese images cost 85 tokens each, regardless of the image size.\n\nExample: 4096 x 8192 image (low detail): The cost is a fixed 85 tokens, because\n\nit's a low detail image, and the size doesn't affect the cost in this mode.\n\nDetail: High resolution mode\n\nHigh detail lets the API see the image in more detail by cropping it into smaller\n\nsquares. Each square uses more tokens to generate text.\n\nThe token cost is calculated by a series of scaling steps:\n\nTokens\n\nText tokens\n\nImage tokens (GPT-4 Turbo with Vision)\n\n17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview 4/5\n\n\ufffd. The image is first scaled to fit within a 2048 x 2048 square while\n\nmaintaining its aspect ratio.\n\n\ufffd. The image is then scaled down so that the shortest side is 768 pixels long.\n\n\ufffd. The image is divided into 512-pixel square tiles, and the number of these\n\ntiles (rounding up for partial tiles) determines the final cost. Each tile costs\n\n170 tokens.\n\n\ufffd. An additional 85 tokens are added to the total cost.\n\nExample: 2048 x 4096 image (high detail)\n\n\ufffd. Initially resized to 1024 x 2048 to fit in the 2048 square.\n\n\ufffd. Further resized to 768 x 1536.\n\n\ufffd. Requires six 512px tiles to cover.\n\n\ufffd. Total cost is 170 \u00d7 6 + 85 = 1105  tokens.\n\nAzure OpenAI is a new product offering on Azure. You can get started with Azure\n\nOpenAI the same way as any other Azure product where you create a resource, or\n\ninstance of the service, in your Azure Subscription. You can read more about Azure's\n\nresource management design""}}]}","Yes, we restrict image uploads to 20MB per image.",AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I delete an image I uploaded to Azure OpenAI?,"Yes, you can delete an image that you uploaded to Azure OpenAI. The image will be automatically deleted after it has been processed by the model[doc0].","No, Azure OpenAI will automatically delete the image after it has been processed by the model.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn"", ""content"": ""How do I get access to Azure OpenAI?\n\nComparing Azure OpenAI and OpenAI\n\nKey concepts\n\nPrompts & completions\n\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\nhttps://aka.ms/oaiapply\nhttps://aka.ms/oaiapply\n\n17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview 3/5\n\nThe completions endpoint is the core component of the API service. This API provides\n\naccess to the model's text-in, text-out interface. Users simply need to provide an input\n\nprompt containing the English text command, and the model will generate a text\n\ncompletion.\n\nHere's an example of a simple prompt and completion:\n\nPrompt: \""\""\"" count to 5 in a for loop \""\""\""\n\nCompletion: for i in range(1, 6): print(i)\n\nAzure OpenAI processes text by breaking it down into tokens. Tokens can be words or\n\njust chunks of characters. For example, the word \u201chamburger\u201d gets broken up into the\n\ntokens \u201cham\u201d, \u201cbur\u201d and \u201cger\u201d, while a short and common word like \u201cpear\u201d is a single\n\ntoken. Many tokens start with a whitespace, for example \u201c hello\u201d and \u201c bye\u201d.\n\nThe total number of tokens processed in a given request depends on the length of your\n\ninput, output and request parameters. The quantity of tokens being processed will also\n\naffect your response latency and throughput for the models.\n\nThe token cost of an input image depends on two main factors: the size of the image\n\nand the detail setting (low or high) used for each image. Here's a breakdown of how it\n\nworks:\n\nDetail: Low resolution mode\n\nLow detail allows the API to return faster responses and consume fewer input\n\ntokens for use cases that don\u2019t require high detail.\n\nThese images cost 85 tokens each, regardless of the image size.\n\nExample: 4096 x 8192 image (low detail): The cost is a fixed 85 tokens, because\n\nit's a low detail image, and the size doesn't affect the cost in this mode.\n\nDetail: High resolution mode\n\nHigh detail lets the API see the image in more detail by cropping it into smaller\n\nsquares. Each square uses more tokens to generate text.\n\nThe token cost is calculated by a series of scaling steps:\n\nTokens\n\nText tokens\n\nImage tokens (GPT-4 Turbo with Vision)\n\n17/12/2023, 11:50 What is Azure OpenAI Service? - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview 4/5\n\n\ufffd. The image is first scaled to fit within a 2048 x 2048 square while\n\nmaintaining its aspect ratio.\n\n\ufffd. The image is then scaled down so that the shortest side is 768 pixels long.\n\n\ufffd. The image is divided into 512-pixel square tiles, and the number of these\n\ntiles (rounding up for partial tiles) determines the final cost. Each tile costs\n\n170 tokens.\n\n\ufffd. An additional 85 tokens are added to the total cost.\n\nExample: 2048 x 4096 image (high detail)\n\n\ufffd. Initially resized to 1024 x 2048 to fit in the 2048 square.\n\n\ufffd. Further resized to 768 x 1536.\n\n\ufffd. Requires six 512px tiles to cover.\n\n\ufffd. Total cost is 170 \u00d7 6 + 85 = 1105  tokens.\n\nAzure OpenAI is a new product offering on Azure. You can get started with Azure\n\nOpenAI the same way as any other Azure product where you create a resource, or\n\ninstance of the service, in your Azure Subscription. You can read more about Azure's\n\nresource management design""}}]}",we'll delete the image for you automatically after it has been processed by the model,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Does Azure OpenAI on your data support vector embeddings when indexing data?,"Yes, Azure OpenAI on your data supports vector embeddings when indexing data[doc1][doc4]. When selecting ""Azure Blob Container"", ""Azure AI Search"", or ""Upload files"" as the data source, you have the option to choose an Ada embedding model deployment to use when ingesting your data. This will create an Azure AI Search index with vector embeddings[doc4]. Vector embeddings are information-dense representations of the semantic meaning of text, and they make it easier to perform tasks like vector similarity search and assessing similarity between text chunks[doc1].","Yes, you can add vector embeddings when indexing your data.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""How can I customize or automate the index\n\ncreation process?\n\nHow can I update my index?\n\nWhat file types does Azure OpenAI on your data\n\nsupport?\n\nIs responsible AI supported by Azure OpenAI on\n\nyour data?\n\nIs there a token limit on the system message?\n\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#schedule-automatic-index-refreshes\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#data-formats-and-file-types\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=text\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 12/13\n\nAzure OpenAI on your data currently doesn't support function calling.\n\nYou must send queries in the same language of your data. Your data can be in any of\n\nthe languages supported by Azure AI Search.\n\nWhen you select \""Azure AI Search\"" as the data source, you can choose to apply\n\nsemantic search. If you select \""Azure Blob Container\"" or \""Upload files\"" as the data\n\nsource, you can create the index as usual. Afterwards you would re-ingest the data using\n\nthe \""Azure AI Search\"" option to select the same index and apply Semantic Search. You\n\nwill then be ready to chat on your data with semantic search applied.\n\nWhen you select \""Azure Blob Container\"", \""Azure AI Search\"", or \""Upload files\"" as the data\n\nsource, you can also select an Ada embedding model deployment to use when\n\ningesting your data. This will create an Azure AI Search index with vector embeddings.\n\nIndex creation can fail when adding embeddings to your index if the rate limit on your\n\nAda embedding model deployment is too low, or if you have a very large set of\n\ndocuments. You can use this script provided on GitHub  to create the index with\n\nembeddings manually.\n\nDoes Azure OpenAI on your data support\n\nfunction calling?\n\nDoes the query language and the data source\n\nlanguage need to be the same?\n\nIf Semantic Search is enabled for my Azure AI\n\nSearch resource, will it be automatically applied\n\nto Azure OpenAI on your data in the Azure\n\nOpenAI Studio?\n\nHow can I add vector embeddings when\n\nindexing my data?\n\nWhy is index creation failing after I added an\n\nembedding model?\n\nhttps://learn.microsoft.com/en-us/azure/search/search-language-support\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""How can I customize or automate the index\n\ncreation process?\n\nHow can I update my index?\n\nWhat file types does Azure OpenAI on your data\n\nsupport?\n\nIs responsible AI supported by Azure OpenAI on\n\nyour data?\n\nIs there a token limit on the system message?\n\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#schedule-automatic-index-refreshes\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data#data-formats-and-file-types\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=text\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 12/13\n\nAzure OpenAI on your data currently doesn't support function calling.\n\nYou must send queries in the same language of your data. Your data can be in any of\n\nthe languages supported by Azure AI Search.\n\nWhen you select \""Azure AI Search\"" as the data source, you can choose to apply\n\nsemantic search. If you select \""Azure Blob Container\"" or \""Upload files\"" as the data\n\nsource, you can create the index as usual. Afterwards you would re-ingest the data using\n\nthe \""Azure AI Search\"" option to select the same index and apply Semantic Search. You\n\nwill then be ready to chat on your data with semantic search applied.\n\nWhen you select \""Azure Blob Container\"", \""Azure AI Search\"", or \""Upload files\"" as the data\n\nsource, you can also select an Ada embedding model deployment to use when\n\ningesting your data. This will create an Azure AI Search index with vector embeddings.\n\nIndex creation can fail when adding embeddings to your index if the rate limit on your\n\nAda embedding model deployment is too low, or if you have a very large set of\n\ndocuments. You can use this script provided on GitHub  to create the index with\n\nembeddings manually.\n\nDoes Azure OpenAI on your data support\n\nfunction calling?\n\nDoes the query language and the data source\n\nlanguage need to be the same?\n\nIf Semantic Search is enabled for my Azure AI\n\nSearch resource, will it be automatically applied\n\nto Azure OpenAI on your data in the Azure\n\nOpenAI Studio?\n\nHow can I add vector embeddings when\n\nindexing my data?\n\nWhy is index creation failing after I added an\n\nembedding model?\n\nhttps://learn.microsoft.com/en-us/azure/search/search-language-support\nhttps://go.microsoft.com/fwlink/?linkid=2244395\nhttps://go.microsoft.com/fwlink/?linkid=2244395\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}]}",This will create an Azure AI Search index with vector embeddings,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I use quotа to increase the max token limit of a model?,"Yes, you can use quota to increase the max token limit of a model in the Azure OpenAI Service. However, it's important to note that the quota Tokens-Per-Minute (TPM) allocation is not directly related to the max input token limit of a model. The model input token limits are defined in the models table and are not impacted by changes made to TPM[doc0].","No, the max input token limit of a model is not impacted by changes made to TPM.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service quotas and limits - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/quotas-limits 3/3\n\nCentral\n\nNorth Central US, Australia East, East US 2,\n\nCanada East, Japan East, UK South, Switzerland\n\nNorth\n\n350 K\n\nFine-tuning models (babbage-\n\n002, davinci-002, gpt-35-turbo-\n\n0613)\n\nNorth Central US, Sweden Central 50 K\n\nall other models East US, South Central US, West Europe, France\n\nCentral\n\n120 K\n\nTo minimize issues related to rate limits, it's a good idea to use the following techniques:\n\nImplement retry logic in your application.\n\nAvoid sharp changes in the workload. Increase the workload gradually.\n\nTest different load increase patterns.\n\nIncrease the quota assigned to your deployment. Move quota from another\n\ndeployment, if necessary.\n\nQuota increase requests can be submitted from the Quotas page of Azure OpenAI\n\nStudio. Please note that due to overwhelming demand, quota increase requests are\n\nbeing accepted and will be filled in the order they are received. Priority will be given to\n\ncustomers who generate traffic that consumes the existing quota allocation, and your\n\nrequest may be denied if this condition is not met.\n\nFor other rate limits, please submit a service request.\n\nExplore how to manage quota for your Azure OpenAI deployments. Learn more about\n\nthe underlying models that power Azure OpenAI.\n\nGeneral best practices to remain within rate limits\n\nHow to request increases to the default quotas and limits\n\nNext steps\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models""}}, {""[doc2]"": {""title"": ""17/12/2023, 11:51 Azure OpenAI Service provisioned throughput - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:51 Azure OpenAI Service provisioned throughput - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/provisioned-throughput 1/3\n\nWhat is provisioned throughput?\nArticle \u2022 11/21/2023\n\nThe provisioned throughput capability allows you to specify the amount of throughput\n\nyou require for your application. The service then provisions the necessary compute and\n\nensures it is ready for you. Throughput is defined in terms of provisioned throughput\n\nunits (PTU) which is a normalized way of representing an amount of throughput for your\n\ndeployment. Each model-versions pair requires different amounts of PTU to deploy and\n\nprovide different amounts of throughput per PTU.\n\nPredictable performance: stable max latency and throughput for uniform\n\nworkloads.\n\nReserved processing capacity: A deployment configures the amount of\n\nthroughput. Once deployed, the throughput is available whether used or not.\n\nCost savings: High throughput workloads may provide cost savings vs token-\n\nbased consumption.\n\nAn Azure OpenAI Deployment is a unit of management for a specific OpenAI Model. A\n\ndeployment provides customer access to a model for inference and integrates\n\nadditional features like Content Moderation (See content moderation documentation).\n\nTopic Provisioned\n\nWhat is it? Provides guaranteed throughput at smaller increments than the existing\n\nprovisioned offer. Deployments will have a consistent max latency for a given\n\nmodel-version\n\nWhat does the provisioned deployment type\n\nprovide?\n\n\uff17 Note\n\nProvisioned throughput units (PTU) are different from standard quota in Azure\n\nOpenAI and are not available by default. To learn more about this offering contact\n\nyour Microsoft Account Team.\n\nWhat do you get?\n\n\uff89 Expand table\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-filter\n\n17/12/2023, 11:51 Azure OpenAI Service provisioned throughput - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/provisioned-throughput 2/3\n\nTopic Provisioned\n\nWho is it\n\nfor?\n\nCustomers who want guaranteed throughput with minimal latency variance.\n\nQuota Provisioned-managed throughput Units\n\nLatency Max latency constrained\n\nUtilization Provisioned-managed Utilization measure provided in Azure Monitor\n\nEstimating\n\nsize\n\nProvided calculator in the studio & load test script\n\nProvisioned throughput Units (PTU) are units of model processing capacity that\n\ncustomers you can reserve and deploy for processing prompts and generating\n\ncompletions. The minimum PTU deployment, increments, and processing capacity\n\nassociated with each unit varies by model type & version.\n\nWe introduced a new deployment type called ProvisionedManaged which provides\n\nsmaller increments of PTU per deployment. Both types have their own quota, and you\n\nwill only see the options you have been enabled for.\n\nProvisioned throughput quota represents a specific amount of total throughput you can\n\ndeploy. Quota in the Azure OpenAI Service is managed at the subscription level\n\nmeaning that it can be consumed by different resources within that subscription.\n\nQuota is specific to a (deployment type, mode, region) triplet and isn't interchangeable.\n\nMeaning you can't use quota for GPT-4 to deploy GPT-35-turbo. Customers can raise a\n\nsupport request to move the quota across deployment types, models, or regions but we\n\ncan't guarantee that it will be possible.\n\nWhile we make every attempt to ensure that quota is always deployable, quota does not\n\nrepresent a guarantee that the underlying capacity is available for the customer to use.\n\nKey concepts\n\nProvisioned throughput units\n\nDeployment types\n\nQuota\n\n17/12/2023, 11:51 Azure OpenAI Service provisioned throughput - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/provisioned-throughput 3/3\n\nThe service assigns capacity to the customer at deployment time and if capacity is\n\nunavailable the deployment will fail with an out of capacity error""}}]}","No, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit of a model",AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I fine-tune the image capabilities in GPT-4?,"No, you cannot fine-tune the image capabilities in GPT-4 at this time[doc1].","No, fine-tuning the image capabilities of GPT-4 is not supported at this time.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}]}",we don't support fine-tuning the image capabilities of GPT-4 at this time,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I use Azure OpenAI to understand image metadata?,"No, Azure OpenAI does not receive image metadata[doc0].","No, GPT-4 Turbo with Vision does not understand image metadata.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 8/13\n\nIf a customized (fine-tuned) model is deployed for more than 15 days during which no\n\ncompletions or chat completions calls are made to it, the deployment is automatically\n\ndeleted (and no further hosting charges are incurred for that deployment). The\n\nunderlying customized model remains available and can be redeployed at any time. To\n\nlearn more, check out the how-to-article.\n\nThere are currently two different REST APIs that allow model deployment. For the latest\n\nmodel deployment features such as the ability to specify a model version during\n\ndeployment for models like text-embedding-ada-002 Version 2, use the Deployments -\n\nCreate Or Update REST API call.\n\nNo, quota Tokens-Per-Minute (TPM) allocation isn't related to the max input token limit\n\nof a model. Model input token limits are defined in the models table and aren't\n\nimpacted by changes made to TPM.\n\nNo, we don't support fine-tuning the image capabilities of GPT-4 at this time.\n\nNo, you can use dall-e-3  to generate images and gpt-4-visual-preview  to\n\nunderstand images.\n\nWe currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-\n\nanimated GIF (.gif).\n\nWhy was my fine-tuned model deployment\n\ndeleted?\n\nHow do I deploy a model with the REST API?\n\nCan I use quota to increase the max token limit\n\nof a model?\n\nGPT-4 Turbo with Vision\n\nCan I fine-tune the image capabilities in GPT-4?\n\nCan I use GPT-4 to generate images?\n\nWhat type of files can I upload?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?tabs=HTTP\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 9/13\n\nYes, we restrict image uploads to 20MB per image.\n\nNo, we'll delete the image for you automatically after it has been processed by the\n\nmodel.\n\nWe process images at the token level, so each image we process counts towards your\n\ntokens per minute (TPM) limit. See the Image tokens section of the Overview for details\n\non the formula used to determine token count per image.\n\nNo, the model doesn't receive image metadata.\n\nIf an image is ambiguous or unclear, the model will do its best to interpret it. However,\n\nthe results might be less accurate. A good rule of thumb is that if an average human\n\ncan't see the info in an image at the resolutions used in low/high res mode, then the\n\nmodel can't either.\n\nSee the limitations section of the GPT-4 Turbo with Vision how-to guide.\n\nIs there a limit to the size of the image I can\n\nupload?\n\nCan I delete an image I uploaded?\n\nHow do the rate limits for GPT-4 Turbo with\n\nVision work?\n\nCan GPT-4 Turbo with Vision understand image\n\nmetadata?\n\nWhat happens if my image is unclear?\n\nWhat are the known limitations of GPT-4 Turbo\n\nwith Vision?\n\nWeb app\n\nHow can I customize my published web app?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/overview#tokens\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:51 Content Credentials in Azure OpenAI - Azure OpenAI | Microsoft Learn"", ""content"": ""17/12/2023, 11:51 Content Credentials in Azure OpenAI - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-credentials 1/2\n\nContent Credentials\nArticle \u2022 11/28/2023\n\nWith the improved quality of content from generative AI models, there is an increased\n\nneed for more transparency on the origin of AI-generated content. All AI-generated\n\nimages from the Azure OpenAI service now include Content Credentials, a tamper-\n\nevident way to disclose the origin and history of content. Content Credentials are based\n\non an open technical specification from the Coalition for Content Provenance and\n\nAuthenticity (C2PA) , a Joint Development Foundation project.\n\nContent Credentials in the Azure OpenAI Service provide customers with information\n\nabout the origin of an image generated by the DALL-E series models. This information is\n\nrepresented by a manifest attached to the image. The manifest is cryptographically\n\nsigned by a certificate that traces back to Azure OpenAI Service.\n\nThe manifest contains several key pieces of information:\n\nField name Field content\n\n\""description\"" This field has a value of \""AI Generated Image\""  for all DALL-E model\n\ngenerated images, attesting to the AI-generated nature of the image.\n\n\""softwareAgent\"" This field has a value of \""Azure OpenAI DALL-E\""  for all images generated by\n\nDALL-E series models in the Azure OpenAI service.\n\n\""when\"" The timestamp of when the Content Credentials were created.\n\nContent Credentials in the Azure OpenAI Service can help people understand when\n\nvisual content is AI-generated. For more information on how to responsibly build\n\nsolutions with Azure OpenAI service image-generation models, visit the Azure OpenAI\n\ntransparency note.\n\nCustomers may leverage Content Credentials by:\n\nWhat are Content Credentials?\n\n\uff89 Expand table\n\nHow do I leverage Content Credentials in my\n\nsolution today?\n\nhttps://www.c2pa.org/\nhttps://www.c2pa.org/\nhttps://www.c2pa.org/\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?tabs=text\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?tabs=text\n\n17/12/2023, 11:51 Content Credentials in Azure OpenAI - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/content-credentials 2/2\n\nEnsuring that their AI generated images contain Content Credentials\n\nNo additional set-up is necessary. Content Credentials are automatically applied to all\n\ngenerated images from DALL\u00b7E in the Azure OpenAI Service.\n\nVerifying that an image has Content Credentials\n\nThere are two recommended ways today to check the Credential of an image generated\n\nby Azure OpenAI DALL-E models:\n\n\ufffd. Content Credentials Verify webpage (contentcredentials.org/verify): This is a tool\n\nthat allows users to inspect the Content Credentials of a piece of content. If an\n\nimage was generated by DALL-E in Azure OpenAI, the tool will display that its\n\nContent Credentials were issued by Microsoft Corporation alongside the date and\n\ntime of issuance.\n\nThis page shows that an image generated by Azure OpenAI DALL-E has Content\n\nCredentials issued by Microsoft.\n\n\ufffd. Content Authenticity Initiative (CAI) open-source tools: The CAI provides multiple\n\nopen-source tools that validate and display C2PA Content Credentials. Find the\n\ntool right for your application and get started here .\n\nhttps://opensource.contentauthenticity.org/\nhttps://opensource.contentauthenticity.org/""}}]}","No, the model doesn't receive image metadata",AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Can I apply for new use cases for Azure OpenAI?,"Yes, you can apply for new use cases for Azure OpenAI. Previously, the process for adding new use cases required customers to reapply to the service. However, there is now a new process that allows you to quickly add new use cases to your use of the service. This process follows the established Limited Access process within Azure AI services. Existing customers can attest to any and all new use cases [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/faq) [doc0][doc1].","Yes, customers can apply for new use cases for their service.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 What's new in Azure OpenAI Service? - Azure AI services | Microsoft Learn"", ""content"": ""If a customized (fine-tuned)\n\nmodel is deployed for more than fifteen (15) days during which no completions or\n\nchat completions calls are made to it, the deployment will automatically be deleted\n\n(and no further hosting charges will be incurred for that deployment). The\n\nunderlying customized model will remain available and can be redeployed at any\n\ntime. To learn more check out the how-to-article.\n\nGPT-4 series models are now available in preview on Azure OpenAI. To request\n\naccess, existing Azure OpenAI customers can apply by filling out this form . These\n\nmodels are currently available in the East US and South Central US regions.\n\nNew Chat Completion API for GPT-35-Turbo and GPT-4 models released in\n\npreview on 3/21. To learn more checkout the updated quickstarts and how-to\n\narticle.\n\nGPT-35-Turbo preview. To learn more checkout the how-to article.\n\nIncreased training limits for fine-tuning: The max training job size (tokens in\n\ntraining file) x (# of epochs) is 2 Billion tokens for all models. We have also\n\nincreased the max training job from 120 to 720 hours.\n\nAdding additional use cases to your existing access. \u00a0Previously, the process for\n\nadding new use cases required customers to reapply to the service. Now, we're\n\nreleasing a new process that allows you to quickly add new use cases to your use\n\nof the service. This process follows the established Limited Access process within\n\nAzure AI services. Existing customers can attest to any and all new use cases\n\nhere . Please note that this is required anytime you would like to use the service\n\nfor a new use case you did not originally apply for.\n\n.NET SDK(inference) preview release  | Samples\n\nTerraform SDK update  to support Azure OpenAI management operations.\n\nInserting text at the end of a completion is now supported with the suffix\n\nparameter.\n\nMarch 2023\n\nFebruary 2023\n\nNew Features\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio#deploy-a-customized-model\nhttps://aka.ms/oai/get-gpt4\nhttps://aka.ms/oai/get-gpt4\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\nhttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUM003VEJPRjRSOTZBRVZBV1E5N1lWMk1XUyQlQCN0PWcu\nhttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUM003VEJPRjRSOTZBRVZBV1E5N1lWMk1XUyQlQCN0PWcu\nhttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUM003VEJPRjRSOTZBRVZBV1E5N1lWMk1XUyQlQCN0PWcu\nhttps://www.nuget.org/packages/Azure.AI.OpenAI/1.0.0-beta.3\nhttps://www.nuget.org/packages/Azure.AI.OpenAI/1.0.0-beta.3\nhttps://github.com/Azure/azure-sdk-for-net/tree/main/sdk/openai/Azure.AI""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 1/13\n\nAzure OpenAI Service frequently\nasked questions\nFAQ\n\nIf you can't find answers to your questions in this document, and still need help check\n\nthe Azure AI services support options guide. Azure OpenAI is part of Azure AI services.\n\nAzure OpenAI doesn't use customer data to retrain models. For more information, see\n\nthe Azure OpenAI data, privacy, and security guide.\n\nAzure OpenAI is supported by the latest release of the OpenAI Python library\n\n(version>=1.0) . However, it's important to note migration of your codebase using\n\nopenai migrate  is not supported and will not work with code that targets Azure\n\nOpenAI.\n\nGPT-4 Turbo Preview is the gpt-4  (1106-preview) model. To deploy this model, under\n\nDeployments select model gpt-4. For Model version select 1106-preview. To check\n\nwhich regions this model is available, refer to the models page.\n\nAzure OpenAI supports the latest GPT-4 models. It supports both GPT-4 and GPT-4-32K.\n\nData and Privacy\n\nDo you use my company data to train any of the\n\nmodels?\n\nGeneral\n\nDoes Azure OpenAI work with the latest Python\n\nlibrary released by OpenAI (version>=1.0)?\n\nI can't find GPT-4 Turbo Preview, where is it?\n\nDoes Azure OpenAI support GPT-4?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-support-options?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy?context=/azure/ai-services/openai/context/context\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://pypi.org/project/openai/\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 2/13\n\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3,\n\nCodex, and DALL-E models with the security and enterprise promise of Azure. Azure\n\nOpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth\n\ntransition from one to the other.\n\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while\n\nrunning the same models as OpenAI.\n\nYes, as part of Azure AI services, Azure OpenAI supports VNETs and Private Endpoints.\n\nTo learn more, consult the Azure AI services virtual networking guidance\n\nNo, GPT-4 is designed by OpenAI to be multimodal, but currently only text input and\n\noutput are supported.\n\nPreviously, the process for adding new use cases required customers to reapply to the\n\nservice. Now, we're releasing a new process that allows you to quickly add new use\n\ncases to your use of the service. This process follows the established Limited Access\n\nprocess within Azure AI services. Existing customers can attest to any and all new use\n\ncases here . Note that this is required anytime you would like to use the service for a\n\nnew use case you didn't originally apply for.\n\nThis error typically occurs when you try to send a batch of text to embed in a single API\n\nrequest as an array. Currently Azure OpenAI only supports arrays of embeddings with\n\nmultiple inputs for the text-embedding-ada-002  Version 2 model. This model version\n\nHow do the capabilities of Azure OpenAI\n\ncompare to OpenAI?\n\nDoes Azure OpenAI support VNETs and Private\n\nEndpoints?\n\nDo the GPT-4 models currently support image\n\ninput?\n\nHow do I apply for new use cases?\n\nI'm trying to use embeddings and received the\n\nerror \""InvalidRequestError: Too many inputs""}}, {""[doc2]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 13/13\n\nThe Customer Copyright Commitment is a provision to be included in the December 1,\n\n2023, Microsoft Product Terms that describes Microsoft\u2019s obligation to defend\n\ncustomers against certain third-party intellectual property claims relating to Output\n\nContent. If the subject of the claim is Output Content generated from the Azure OpenAI\n\nService (or any other Generative AI Service that allows customers to configure the safety\n\nsystems), then to receive coverage, customer must have implemented all mitigations\n\nrequired by the Azure OpenAI Service documentation in the offering that delivered the\n\nOutput Content. The required mitigations are documented here and updated on an\n\nongoing basis. For new services, features, models, or use cases, new CCC requirements\n\nwill be posted and take effect at or following the launch of such service, feature, model,\n\nor use case. Otherwise, customers will have six months from the time of publication to\n\nimplement new mitigations to maintain coverage under the CCC. If a customer tenders a\n\nclaim, the customer will be required to demonstrate compliance with the relevant\n\nrequirements. These mitigations are required for Generative AI Services that allow\n\ncustomers to configure the safety systems, including Azure OpenAI Service; they do not\n\nimpact coverage for customers using other Generative AI Services and Copilots.\n\nAzure OpenAI quotas and limits\n\nAzure OpenAI what's new\n\nAzure OpenAI quickstarts\n\nCustomer Copyright Commitment\n\nHow do I obtain coverage under the Customer\n\nCopyright Commitment?\n\nNext steps\n\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/openai/customer-copyright-commitment?context=/azure/ai-services/openai/context/context\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart""}}]}",This process follows the established Limited Access process within Azure AI services,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Is the guest account access issue in Azure OpenAI Studio expected behavior?,"Yes, the guest account access issue in Azure OpenAI Studio is expected behavior[doc1]. When using the default sign-in experience for Azure OpenAI Studio with a guest account that has been granted access to an Azure OpenAI resource, you may be unable to access that resource. To enable access, you can follow these steps:

1. Open a private browser session and navigate to https://oai.azure.com.
2. Instead of immediately entering your guest account credentials, select ""Sign-in options"".
3. Choose ""Sign in to an organization"".
4. Enter the domain name of the organization that granted your guest account access to the Azure OpenAI resource.
5. Sign in with your guest account credentials.

By following these steps, you should be able to access the resource via Azure OpenAI Studio[doc1].","Yes, it is expected behavior and there are steps provided to enable access.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""The\n\nmax number of inputs is 16.\"" How do I fix this?\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-virtual-networks?context=/azure/ai-services/openai/context/context\nhttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUM003VEJPRjRSOTZBRVZBV1E5N1lWMk1XUyQlQCN0PWcu\nhttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUM003VEJPRjRSOTZBRVZBV1E5N1lWMk1XUyQlQCN0PWcu\nhttps://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUM003VEJPRjRSOTZBRVZBV1E5N1lWMk1XUyQlQCN0PWcu\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 3/13\n\nsupports an array consisting of up to 16 inputs per API request. The array can be up to\n\n8191 tokens in length when using the text-embedding-ada-002 (Version 2) model.\n\nCheck out our introduction to prompt engineering. While these models are powerful,\n\ntheir behavior is also very sensitive to the prompts they receive from the user. This\n\nmakes prompt construction an important skill to develop. After you've completed the\n\nintroduction, check out our article on advanced prompt engineering techniques.\n\nThis is expected behavior when using the default sign-in experience for the Azure\n\nOpenAI Studio .\n\nTo access Azure OpenAI Studio from a guest account that has been granted access to an\n\nAzure OpenAI resource:\n\n\ufffd. Open a private browser session and then navigate to https://oai.azure.com .\n\n\ufffd. Rather than immediately entering your guest account credentials instead select\n\nSign-in options\n\n\ufffd. Now select Sign in to an organization\n\n\ufffd. Enter the domain name of the organization that granted your guest account\n\naccess to the Azure OpenAI resource.\n\n\ufffd. Now sign-in with your guest account credentials.\n\nYou should now be able to access the resource via the Azure OpenAI Studio.\n\nAlternatively if you're signed into the Azure portal  from the Azure OpenAI resource's\n\nOverview pane you can select Go to Azure OpenAI Studio to automatically sign in with\n\nthe appropriate organizational context.\n\nWhere can I read about better ways to use Azure\n\nOpenAI to get the responses I want from the\n\nservice?\n\nMy guest account has been given access to an\n\nAzure OpenAI resource, but I'm unable to access\n\nthat resource in the Azure OpenAI Studio. How\n\ndo I enable access?\n\nWhen I ask GPT-4 which model it's running, it\n\ntells me it's running GPT-3. Why does this\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering\nhttps://oai.azure.com/\nhttps://oai.azure.com/\nhttps://oai.azure.com/\nhttps://oai.azure.com/\nhttps://oai.azure.com/\nhttps://portal.azure.com/\nhttps://portal.azure.com/\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn"", ""content"": ""com/en-us/azure/ai-services/openai/faq 4/13\n\nAzure OpenAI models (including GPT-4) being unable to correctly identify what model is\n\nrunning is expected behavior.\n\nWhy does this happen?\n\nUltimately, the model is performing next token prediction in response to your question.\n\nThe model doesn't have any native ability to query what model version is currently\n\nbeing run to answer your question. To answer this question, you can always go to Azure\n\nOpenAI Studio > Management > Deployments > and consult the model name column\n\nto confirm what model is currently associated with a given deployment name.\n\nThe questions, \""What model are you running?\"" or \""What is the latest model from\n\nOpenAI?\"" produce similar quality results to asking the model what the weather will be\n\ntoday. It might return the correct result, but purely by chance. On its own, the model has\n\nno real-world information other than what was part of its training/training data. In the\n\ncase of GPT-4, as of August 2023 the underlying training data goes only up to\n\nSeptember 2021. GPT-4 wasn't released until March 2023, so barring OpenAI releasing a\n\nnew version with updated training data, or a new version that is fine-tuned to answer\n\nthose specific questions, it's expected behavior for GPT-4 to respond that GPT-3 is the\n\nlatest model release from OpenAI.\n\nIf you wanted to help a GPT based model to accurately respond to the question \""what\n\nmodel are you running?\"", you would need to provide that information to the model\n\nthrough techniques like prompt engineering of the model's system message, Retrieval\n\nAugmented Generation (RAG) which is the technique used by Azure OpenAI on your\n\ndata where up-to-date information is injected to the system message at query time, or\n\nvia fine-tuning where you could fine-tune specific versions of the model to answer that\n\nquestion in a certain way based on model version.\n\nTo learn more about how GPT models are trained and work we recommend watching\n\nAndrej Karpathy's talk from Build 2023 on the state of GPT .\n\nThis is expected behavior. The models aren't able to answer questions about\n\nthemselves. If you want to know when the knowledge cutoff for the model's training\n\nhappen?\n\nI asked the model when it's knowledge cutoff is\n\nand it gave me a different answer than what is\n\non the Azure OpenAI model's page. Why does\n\nthis happen?\n\nhttps://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions\nhttps://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2\nhttps://learn.microsoft.com/en-us/azure/machine-learning/concept-retrieval-augmented-generation?view=azureml-api-2\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?pivots=programming-language-studio\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A\n\n17/12/2023, 11:50 Azure OpenAI Service frequently asked questions - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/faq 5/13\n\ndata is, consult the models page.\n\nThis is expected behavior. First there's no guarantee that every recent event that has\n\noccurred was part of the model's training data""}}]}",This is expected behavior when using the default sign-in experience,AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],Are the capabilities of Azure OpenAI comparable to OpenAI?,"Yes, the capabilities of Azure OpenAI are comparable to OpenAI. Azure OpenAI Service provides customers with advanced language AI models such as OpenAI GPT-3, Codex, and DALL-E, while offering the security and enterprise promise of Azure[doc0]. Azure OpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth transition between the two platforms[doc0][doc1]. With Azure OpenAI, customers can leverage the same models as OpenAI while benefiting from the security capabilities of Microsoft Azure[doc0][doc1].","Yes, Azure OpenAI offers advanced language AI with the security and enterprise promise of Azure.","{""retrieved_documents"": [{""[doc0]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service quotas and limits - Azure AI services | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service quotas and limits - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits 1/3\n\nAzure OpenAI Service quotas and limits\nArticle \u2022 12/12/2023\n\nThis article contains a quick reference and a detailed description of the quotas and limits\n\nfor Azure OpenAI in Azure AI services.\n\nThe following sections provide you with a quick guide to the default quotas and limits\n\nthat apply to Azure OpenAI:\n\nLimit Name Limit Value\n\nOpenAI resources per region per Azure\n\nsubscription\n\n30\n\nDefault DALL-E 2 quota limits 2 concurrent requests\n\nDefault DALL-E 3 quota limits 2 capacity units (6 requests per minute)\n\nMaximum prompt tokens per request Varies per model. For more information, see Azure\n\nOpenAI Service models\n\nMax fine-tuned model deployments 5\n\nTotal number of training jobs per resource 100\n\nMax simultaneous running training jobs\n\nper resource\n\n1\n\nMax training jobs queued 20\n\nMax Files per resource 30\n\nTotal size of all files per resource 1 GB\n\nMax training job time (job will fail if\n\nexceeded)\n\n720 hours\n\nMax training job size (tokens in training\n\nfile) x (# of epochs)\n\n2 Billion\n\nMax size of all files per upload (Azure\n\nOpenAI on your data)\n\n16 MB\n\nQuotas and limits reference\n\n\uff89 Expand table\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models\n\n17/12/2023, 11:50 Azure OpenAI Service quotas and limits - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits 2/3\n\nThe default quota for models varies by model and region. Default quota limits are\n\nsubject to change.\n\nModel Regions Tokens per\n\nminute\n\ngpt-35-turbo East US, South Central US, West Europe, France\n\nCentral, UK South\n\n240 K\n\nNorth Central US, Australia East, East US 2,\n\nCanada East, Japan East, Sweden Central,\n\nSwitzerland North\n\n300 K\n\ngpt-35-turbo-16k East US, South Central US, West Europe, France\n\nCentral, UK South\n\n240 K\n\nNorth Central US, Australia East, East US 2,\n\nCanada East, Japan East, Sweden Central,\n\nSwitzerland North\n\n300 K\n\ngpt-35-turbo-instruct East US, Sweden Central 240 K\n\ngpt-35-turbo (1106) Australia East, Canada East, France Central,\n\nSouth India, Sweden Central, UK South, West US\n\n120 K\n\ngpt-4 East US, South Central US, France Central 20 K\n\nNorth Central US, Australia East, East US 2,\n\nCanada East, Japan East, UK South, Sweden\n\nCentral, Switzerland North\n\n40 K\n\ngpt-4-32k East US, South Central US, France Central 60 K\n\nNorth Central US, Australia East, East US 2,\n\nCanada East, Japan East, UK South, Sweden\n\nCentral, Switzerland North\n\n80 K\n\ngpt-4 (1106-preview)\n\nGPT-4 Turbo\n\nAustralia East, Canada East, East US 2, France\n\nCentral, UK South, West US\n\n80 K\n\nSouth India, Norway East, Sweden Central 150 K\n\ngpt-4 (vision-preview)\n\nGPT-4 Turbo with Vision\n\nSweden Central, Switzerland North, Australia\n\nEast, West US\n\n10 K\n\ntext-embedding-ada-002 East US, South Central US, West Europe, France 240 K\n\nRegional quota limits\n\n\uff89 Expand table\n\n17/12/2023, 11:50 Azure OpenAI Service quotas and limits - Azure AI services | Microsoft Learn\n\nhttps://learn.microsoft""}}, {""[doc1]"": {""title"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn"", ""content"": ""17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 1/8\n\nAzure OpenAI Service models\nArticle \u2022 12/12/2023\n\nAzure OpenAI Service is powered by a diverse set of models with different capabilities\n\nand price points. Model availability varies by region. For GPT-3 and other models\n\nretiring in July 2024, see Azure OpenAI Service legacy models.\n\nModels Description\n\nGPT-4 A set of models that improve on GPT-3.5 and can understand and generate\n\nnatural language and code.\n\nGPT-3.5 A set of models that improve on GPT-3 and can understand and generate\n\nnatural language and code.\n\nEmbeddings A set of models that can convert text into numerical vector form to facilitate\n\ntext similarity.\n\nDALL-E\n\n(Preview)\n\nA series of models in preview that can generate original images from natural\n\nlanguage.\n\nWhisper\n\n(Preview)\n\nA series of models in preview that can transcribe and translate speech to text.\n\nGPT-4 can solve difficult problems with greater accuracy than any of OpenAI's previous\n\nmodels. Like GPT-3.5 Turbo, GPT-4 is optimized for chat and works well for traditional\n\ncompletions tasks. Use the Chat Completions API to use GPT-4. To learn more about\n\nhow to interact with GPT-4 and the Chat Completions API check out our in-depth how-\n\nto.\n\ngpt-4\n\ngpt-4-32k\n\ngpt-4-vision\n\nYou can see the token context length supported by each model in the model summary\n\ntable.\n\n\uff89 Expand table\n\nGPT-4 and GPT-4 Turbo Preview\n\nGPT-3.5\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/legacy-models\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt\n\n17/12/2023, 11:50 Azure OpenAI Service models - Azure OpenAI | Microsoft Learn\n\nhttps://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models 2/8\n\nGPT-3.5 models can understand and generate natural language or code. The most\n\ncapable and cost effective model in the GPT-3.5 family is GPT-3.5 Turbo, which has been\n\noptimized for chat and works well for traditional completions tasks as well. GPT-3.5\n\nTurbo is available for use with the Chat Completions API. GPT-3.5 Turbo Instruct has\n\nsimilar capabilities to text-davinci-003  using the Completions API instead of the Chat\n\nCompletions API. We recommend using GPT-3.5 Turbo and GPT-3.5 Turbo Instruct over\n\nlegacy GPT-3.5 and GPT-3 models.\n\ngpt-35-turbo\n\ngpt-35-turbo-16k\n\ngpt-35-turbo-instruct\n\nYou can see the token context length supported by each model in the model summary\n\ntable.\n\nTo learn more about how to interact with GPT-3.5 Turbo and the Chat Completions API\n\ncheck out our in-depth how-to.\n\nThe previous embeddings models have been consolidated into the following new\n\nreplacement model:\n\ntext-embedding-ada-002\n\nThe DALL-E models, currently in preview, generate images from text prompts that the\n\nuser provides.\n\nEmbeddings\n\n\uff09 Important\n\nWe strongly recommend using text-embedding-ada-002 (Version 2) . This\n\nmodel/version provides parity with OpenAI's text-embedding-ada-002 . To learn\n\nmore about the improvements offered by this model, please refer to OpenAI's blog\n\npost . Even if you are currently using Version 1 you should migrate to Version 2 to\n\ntake advantage of the latest weights/updated token limit""}}]}","With Azure OpenAI, customers get the security capabilities of Microsoft Azure while running the same models as OpenAI",AzureOpenAIKnowledgeBase,AzureOpenAIKnowledgeBase
[],How many subscriptions do I currently have?,You currently have 3 subscriptions. [^1^],"You have 3 subscriptions. [Citation: ""subscription_count"":3]","{""current_spend_in_USD"":""$50.24"",""current_vm_count"":19,""subscription_count"":3}",3,Inventory_SQL,Inventory_SQL
[],What number of subscriptions do I have right now in Azure?,You currently have 3 subscriptions in Azure. [^1^],"You currently have 3 subscriptions in Azure. [Citation: ""subscription_count"":3]","{""current_spend_in_USD"":""$50.24"",""current_vm_count"":19,""subscription_count"":3}",3,Inventory_SQL,Inventory_SQL
[],What is my current spend?,"Your current spend is $50.24. [Citation: ""current_spend_in_USD"":""$50.24""]","Your current spend is $50.24. [Citation: ""current_spend_in_USD"":""$50.24""]","{""current_spend_in_USD"":""$50.24"",""current_vm_count"":19,""subscription_count"":3}",50.24,Inventory_SQL,Inventory_SQL
[],What is my current spend currently in Azure?,"Your current spend in Azure is $50.24. [Citation: ""current_spend_in_USD"":""$50.24""]","Your spend in Azure is $50.24. [Citation: ""current_spend_in_USD"":""$50.24""]","{""current_spend_in_USD"":""$50.24"",""current_vm_count"":19,""subscription_count"":3}",50.24,Inventory_SQL,Inventory_SQL
[],I want to know how many virtual machines I have right now.,"You currently have 19 virtual machines. [Citation: ""current_vm_count"":19]","You currently are using 19 virtual machines. [Citation: ""current_vm_count"":19]","{""current_spend_in_USD"":""$50.24"",""current_vm_count"":19,""subscription_count"":3}",19,Inventory_SQL,Inventory_SQL